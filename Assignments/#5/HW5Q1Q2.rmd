---
title: 'STAT 511: HW #5 Q:1 & 2'
author: "Rumil Legaspi"
date: "29 March 2021"
output:
  pdf_document: 
    latex_engine: xelatex
  html_notebook: default
  html_document:
    df_print: paged
  word_document: default
---

# Multiple Regression & Brand Preference Dataset

### Setting up data

```{r, collapse = TRUE, warning = FALSE, message = FALSE}
library(nortest)
library(olsrr)
library(car)
library(lmtest)
library(MASS)
library(tidyverse)

setwd("C:/Users/RUMIL/Desktop/APU/STAT 511 - Millie Mao (Applied Regression Analysis)/Week 10/Week 10")

brand_data = read.table(file = "Brand.txt", header = FALSE, sep = "")

View(brand_data)

# #Adding headers
names(brand_data) <- c("Rating", "Moisture", "Sweetness")

# names(bank_data) <- c("", "")

#Defining dependent and independent vars
Rating = brand_data$Rating #Y
Moisture = brand_data$Moisture #X1
Sweetness = brand_data$Sweetness #X2
```

+-----------------------------------+----------------------------------------------+-----------------------------------------+
| Response Variable (Y)             | Explanatory Variable 1 ($X_{1}$)             | Explanatory Variable 2 ($X_{2}$)        |
+===================================+==============================================+=========================================+
| "Rating" = Degree of Brand liking | "Moisture" = Moisture content of the product | "Sweetness" = Sweetness of the product. |
+-----------------------------------+----------------------------------------------+-----------------------------------------+
|                                   |                                              |                                         |
+-----------------------------------+----------------------------------------------+-----------------------------------------+

## 1a. Fit a multiple regression model to this dataset. Write down the estimated regression function.

```{r}
#Regressing Rating (response) on Moisture (explanatory) and Sweetness (explanatory).
#Then summarizing our model
brand_lm <- lm(Rating ~ Moisture + Sweetness, data = brand_data)
summary(brand_lm)

```

From summarizing our multiple linear regression model we can see:

$\beta_{0}$ = 37.6500 *(intercept)*

Moisture (Predictor Variable):

$\beta_{1}$ = 4.4250 *(partial slope)*

Sweetness (Predictor Variable):

$\beta_{2}$ = 4.3750 *(partial slope)*

and the estimated regression equation to be:

$\hat{Y}= 37.6500 + 4.4250X + 4.3750X$

## 1b. Interpret the regression coefficients $\hat{\beta_0}$ , $\hat{\beta_1}$, $\hat{\beta_2}$ in words.

### Interpretation of $\hat{\beta_0} = 37.6500$

The intercept $\hat{\beta_0} = 37.6500$ tells us when both explanatory variables, Moisture and Sweetness are at 0, then the our response variable Rating will be at 37.65.

In other words, when both moisture and sweetness are at 0, our brand rating is 37.65%

Assuming our product might have other features, then a rating (intercept) of 37.65 is very much possible and not entirely unrealistic. Although in this scenario, the usefulness of the intercept alone is not very helpful.

### Interpretation of $\hat{\beta_1} = 4.4250$

**The partial slope** $\hat{\beta_1} = 4.4250$ indicates that when holding our other explanatory variable (Sweetness) constant and unchanged, when Moisture increases by 1 unit, we can expect our rating to also increase by 4.425 rating units.

### Interpretation of $\hat{\beta_2} = 4.3750$

**Similarly, when The partial slope** $\hat{\beta_2} = 4.3750$ indicates that when holding our other explanatory variable (Moisture) constant and unchanged, when Sweetness increases by 1 unit, we can expect our rating to also increase by 4.3750 rating units.

## 1c. Test if **each of each of the two predictors** (partial slopes) in this regression are significant. Write down the null and alternative hypotheses, decision rule, and conclusion.

### Testing for Individual Paramter Significance Using t-test and p-value

**Null Hypothesis**: ${H_0}$: $\beta_{j} = 0$ (slopes are showing no change), $X_{j}$ **is not** linearly associated with Y, therefore the partial slope is not significant.

**Alternative Hypothesis**: ${H_1}$: $\beta_{j} \neq 0$ (slopes are showing change), $X_{j}$ **is** linearly associated with Y, therefore the partial slope is significant.

#### Testing the significance of Moisture ($\hat{\beta_1} = 4.4250$)

```{r}
#**We can use the qt() to find our critical value and compare with our t-value (test statistic)
# We use 0.95 Because of our **95% confidence interval
qt(0.95, 13)

```

\*\* review on examples when to use two sided tests and to set qt at 0.975 with alpha at 0.05

**t-test:**

We see that because the absolute value of our critical value (1.8317) is less than our t-value (14.695) for Moisture, we **fail to reject** our NULL hypothesis and conclude with our alternative hypothesis, that there our partial slope, **Moisture**, shows overall significance in our model.

**p-value:**

Additionally, because the p-value for Moisture is 1.78e-09 and is less than our alpha (accepted error/significance level) of 0.05 we **fail to reject** our NULL hypothesis and conclude with our alternative hypothesis, that there our partial slope, **Moisture**, shows overall significance in our model.

#### Testing the significance of Sweetness ($\hat{\beta_2} = 4.3750$)

**t-test:**

Using the same critical value [1] 1.8317, we see that the absolute value of our critical value (1.8317) is less than our t-value (6.498) for Sweetness, we **fail to reject** our NULL hypothesis and conclude with our alternative hypothesis, that there our partial slope, **Sweetness**, shows overall significance in our model.

**p-value:**

Additionally, because the p-value for Sweetness is 2.01e-05 and is less than our alpha (accepted error/significance level) of 0.05 we **fail to reject** our NULL hypothesis and conclude with our alternative hypothesis, that there our partial slope, **Sweetness**, shows overall significance in our model.

## 1d. Find the 95% confidence intervals of the regression model coefficients $\hat{\beta_1}$, $\hat{\beta_2}$.

```{r}
#Since confidence level is 95%, we use alpha at 0.05. 
alpha <- 0.05

#constructing our 95% confidence interval
confint(brand_lm, level = 1 - alpha)
##** if alt hypo is not equal to zero then that would be a two tail because its considering both  directions, less than and greater than right? 
```

This output reads that within our 95% confidence interval of from 2.5% (the lower limit of our interval) to 97.5% (the upper limit of our interval), our *intercept* and **partial slopes** are both found within the listed intervals.

In this case if we repeat this experiment many times, we are 95% confident that our interval captures the true population parameter of our partial slopes $\beta_{1}$ and $\beta_{2}$ will be between the intervals 3.774 to 5.075530 and 2.920 to 5.582 **RESPECTIVELYY**, with an $\alpha$ (accepted error) of 5%.

\#\#2a. Obtain the ANOVA table for your multiple refression model in Question 1.

```{r}
anova(brand_lm)
```

\#\#2b. Compute the $R^2$ and adjusted $R^2$ using the ANOVA table.

To compute the $R^2$ we add the Sum of Squares of both of our explanatory variables (SSR) and divide by the Sum of squares of our total model (SST)

```{r}
SSR <- 1566.45 + 306.25
SST <- 1566.45 + 306.25 + 94.30

R_squared = SSR/SST
R_squared
```

\#\#2c. Interpret the adjusted $R^2$ you computed in Part b.

Adjusted R squared is the colectie explainability of taking into account redundant or otherwise useless variables into account.

\#\#2d. Conduct an F-test for overall model significance using the ANOVA table. Write down the null and alternative hypotheses, decision rule, and conclusion. The F-distribution critical value at 5% $F_{0.05,2,13}$

**Null Hypothesis**: ${H_0}$: $\beta_{1}=\beta_{2} = 0$ (slopes are showing no change), **does not** show overall model significance \*\*between our partial slopes.

**Alternative Hypothesis**: ${H_1}$: $\beta_{1}=\beta_{2} \neq 0$ (slopes are showing change), **shows** overall model significance \*\*between our partial slopes.

Computing F statistic and comparing with critical value

F statistic = Mean squared regression (MSR) / Mean squared error (MSE) MSR and MSE can be found in the ANOVA table

**recall:**

![](pic2.PNG)

```{r}


```

P-value:
